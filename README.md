# AI Contraception Counseling System

**Graduate Capstone Project**
An AI-powered contraception counseling system using RAG (Retrieval-Augmented Generation) grounded in WHO Family Planning Handbook 2022 and BCS+ Toolkit guidelines.

[![Status](https://img.shields.io/badge/status-production--ready-green)]()
[![Python](https://img.shields.io/badge/python-3.10+-blue)]()
[![License](https://img.shields.io/badge/license-MIT-blue)]()

---

## ğŸ¯ Overview

This project implements a comprehensive AI system for evidence-based contraception counseling with:

- âœ… **RAG Pipeline**: Guideline-grounded responses from 5,460 WHO/BCS+ document chunks
- âœ… **Multi-Language Support**: English, French, and Kinyarwanda with language-specific model routing
- âœ… **Memory Management**: Session-based conversation history and cross-session user profiles
- âœ… **Privacy-First Design**: Anonymous IDs, opt-in data collection, GDPR compliance
- âœ… **Comprehensive Evaluation**: BERTScore, hallucination detection, citation accuracy
- âœ… **Production-Ready**: FastAPI, Docker, extensive testing

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- [Ollama](https://ollama.ai) installed
- 8GB+ RAM (for LLM models)
- 10GB+ disk space

### Installation

```bash
# 1. Clone repository
git clone <repository-url>
cd contraception-support-llm

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate  # Mac/Linux
venv\Scripts\activate     # Windows

# 3. Install dependencies
pip install -r requirements.txt

# 4. Download LLM models
ollama pull llama3.2       # English/French (2.0 GB)
ollama pull aya:8b         # Kinyarwanda (4.8 GB) - optional

# 5. Start Ollama server
ollama serve
```

### Running the System

```bash
# Start API server
uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000

# Access at:
# - Web UI: http://localhost:8000
# - API docs: http://localhost:8000/docs
```

---

## ğŸ“Š Experiments

The system includes 6 comprehensive experiments for evaluation:

```bash
# Validate environment
python run_experiments.py --validate

# List all experiments
python run_experiments.py --list

# Run all experiments (2-3 hours)
python run_experiments.py --all

# Run specific experiments
python run_experiments.py --exp 1 2 3
```

**Experiments**:
1. **Baseline Knowledge** (10-15 min) - LLM knowledge without RAG
2. **Anchored Prompts** (10-15 min) - Strict guideline following
3. **RAG Comparison** (15-20 min) - RAG vs non-RAG performance
4. **Long Session Forgetting** (20-30 min) - Memory across long conversations
5. **Multi-Session Memory** (20-30 min) - Cross-session user profiles
6. **Adherence RL** (30-60 min) - Reinforcement learning for reminders

See [READY_FOR_EXPERIMENTS.md](READY_FOR_EXPERIMENTS.md) for detailed guide.

---

## ğŸ“ Project Structure

```
contraception-support-llm/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml                    # Central configuration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ who/                           # WHO FP Handbook PDFs
â”‚   â”œâ”€â”€ bcs/                           # BCS+ Toolkit PDFs
â”‚   â”œâ”€â”€ synthetic/                     # Synthetic evaluation datasets
â”‚   â”œâ”€â”€ processed/vector_store/        # FAISS index (5,460 chunks)
â”‚   â”œâ”€â”€ memory/                        # Conversation & profile storage
â”‚   â””â”€â”€ collected/                     # Opt-in data collection
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/main.py                    # FastAPI application (21 endpoints)
â”‚   â”œâ”€â”€ rag/                           # RAG pipeline components
â”‚   â”‚   â”œâ”€â”€ rag_pipeline.py            # Main orchestrator
â”‚   â”‚   â”œâ”€â”€ retriever.py               # FAISS retrieval
â”‚   â”‚   â”œâ”€â”€ generator.py               # LLM generation
â”‚   â”‚   â”œâ”€â”€ embeddings.py              # Sentence transformers
â”‚   â”‚   â””â”€â”€ vector_store.py            # FAISS wrapper
â”‚   â”œâ”€â”€ memory/                        # Memory management
â”‚   â”‚   â”œâ”€â”€ memory_manager.py          # Orchestrator
â”‚   â”‚   â”œâ”€â”€ conversation_memory.py     # Session tracking
â”‚   â”‚   â””â”€â”€ user_profile.py            # User profiles
â”‚   â”œâ”€â”€ evaluation/                    # Evaluation framework
â”‚   â”‚   â”œâ”€â”€ evaluator.py               # SystemEvaluator
â”‚   â”‚   â””â”€â”€ metrics.py                 # BERTScore, hallucination detection
â”‚   â”œâ”€â”€ adherence/                     # Adherence support (LinUCB RL)
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ multilang_llm_client.py    # Language-specific routing
â”‚       â”œâ”€â”€ data_collection.py         # Privacy-preserving collection
â”‚       â””â”€â”€ logger.py                  # Logging setup
â”œâ”€â”€ experiments/                       # 6 experiment scripts
â”œâ”€â”€ static/                            # Web UI (HTML/CSS/JS)
â”œâ”€â”€ results/                           # Experiment outputs
â”œâ”€â”€ run_experiments.py                 # Experiment runner
â”œâ”€â”€ requirements.txt                   # Python dependencies
â””â”€â”€ README.md                          # This file
```

---

## ğŸ—ï¸ Architecture

### High-Level System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     USER LAYER                           â”‚
â”‚  Web Browser / Mobile App / API Clients                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ HTTPS/REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FastAPI Application Layer                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Counseling â”‚  â”‚  Memory    â”‚  â”‚ Data Collection â”‚   â”‚
â”‚  â”‚ Endpoints  â”‚  â”‚  Endpoints â”‚  â”‚ (GDPR)          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           RAG Pipeline with Memory                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚Retriever â”‚â†’ â”‚Generator â”‚â†’ â”‚  Memory  â”‚â†’ Response    â”‚
â”‚  â”‚(FAISS)   â”‚  â”‚(Multilangâ”‚  â”‚ Manager  â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vector  â”‚  â”‚    Ollama    â”‚  â”‚  Memory  â”‚
â”‚  Store  â”‚  â”‚    Server    â”‚  â”‚  Storage â”‚
â”‚ (5.4K)  â”‚  â”‚ llama3.2/aya â”‚  â”‚  (JSON)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

See [SYSTEM_ARCHITECTURE.md](SYSTEM_ARCHITECTURE.md) for comprehensive architecture documentation.

---

## ğŸ”‘ Key Features

### 1. RAG Pipeline
- **Vector Store**: 5,460 chunks from WHO FP Handbook 2022 + BCS+ Toolkit
- **Embeddings**: all-MiniLM-L6-v2 (384 dimensions)
- **Retrieval**: FAISS with cosine similarity, top-k=5
- **Generation**: Language-specific model routing
- **Citations**: Automatic source attribution

### 2. Multi-Language Support
- **English**: llama3.2 (2.0 GB) - Primary, fully supported
- **French**: llama3.2 - Good performance
- **Kinyarwanda**: aya:8b (4.8 GB) - Eliminates Swahili mixing

Language-specific routing via [MultiLanguageLLMClient](src/utils/multilang_llm_client.py):
```python
LANGUAGE_MODELS = {
    'english': 'llama3.2',
    'french': 'llama3.2',
    'kinyarwanda': 'aya:8b'
}
```

### 3. Memory Management
- **Session-based**: Conversation history per session
- **User Profiles**: Cross-session persistence
- **Summarization**: Auto-condense after 10+ turns
- **Max History**: 20 turns (configurable)

### 4. Privacy & GDPR Compliance
- **Anonymous IDs**: UUID-based, no PII
- **Opt-in Collection**: Disabled by default
- **Right to Access**: Export user data
- **Right to be Forgotten**: Delete user data
- **Transparent**: Clear consent forms

### 5. Evaluation Framework
- **BERTScore**: Semantic similarity (F1, precision, recall)
- **Hallucination Detection**: Context grounding checks
- **Citation Accuracy**: Source verification
- **Safety Fallbacks**: "I don't know" detection
- **Statistical Tests**: Paired t-tests, confidence intervals

---

## ğŸ”§ API Endpoints

### Counseling
```bash
# Submit question
POST /counsel/query
{
  "question": "What is emergency contraception?",
  "language": "english",
  "session_id": "uuid",
  "user_id": "uuid"
}

# Submit feedback
POST /counsel/feedback

# Get conversation history
GET /counsel/conversation/{session_id}

# Delete conversation
DELETE /counsel/conversation/{session_id}
```

### Memory Management
```bash
# Create/update user profile
POST /memory/profiles

# Get user profile
GET /memory/profiles/{user_id}

# Update preferences
PUT /memory/profiles/{user_id}/preferences
```

### GDPR Compliance
```bash
# Export all user data
GET /memory/users/{user_id}/export

# Delete all user data
DELETE /memory/users/{user_id}
```

### Utilities
```bash
# Health check
GET /health

# System statistics
GET /stats

# API documentation
GET /docs
```

See [SYSTEM_ARCHITECTURE.md](SYSTEM_ARCHITECTURE.md) for complete API documentation.

---

## ğŸ“ˆ Evaluation Results

### Key Metrics
| Metric | Value | Method |
|--------|-------|--------|
| **BERTScore F1** | TBD | Semantic similarity |
| **Hallucination Rate** | TBD | Context grounding |
| **Citation Accuracy** | TBD | Source verification |
| **Response Latency** | 2-6s | End-to-end |
| **Memory Retention** | TBD | Across sessions |

### Experiment Coverage
- âœ… Baseline knowledge assessment
- âœ… Anchored prompt evaluation
- âœ… RAG vs non-RAG comparison
- âœ… Long-session memory testing
- âœ… Multi-session profile consistency
- âœ… Adherence optimization (LinUCB)

Run experiments to generate metrics:
```bash
python run_experiments.py --all
```

---

## ğŸ’» Technology Stack

| Component | Technology | Version |
|-----------|-----------|---------|
| **Backend** | FastAPI | 0.115.5 |
| **Server** | Uvicorn | 0.32.1 |
| **LLM Inference** | Ollama | Latest |
| **Models** | llama3.2, aya:8b | Latest |
| **Embeddings** | Sentence Transformers | 3.3.1 |
| **Vector DB** | FAISS | 1.9.0 |
| **Evaluation** | BERTScore | 0.3.13 |
| **Stats** | SciPy, Statsmodels | Latest |
| **Frontend** | Vanilla JS | - |
| **Logging** | Loguru | 0.7.3 |

---

## ğŸ› ï¸ Configuration

Edit [configs/config.yaml](configs/config.yaml) to customize:

```yaml
# Model settings
models:
  llm:
    provider: "ollama"
    model_name: "llama3.2"
    temperature: 0.1
    max_tokens: 1024

# RAG settings
rag:
  retrieval:
    top_k: 5
    score_threshold: 0.7
  chunking:
    chunk_size: 250
    chunk_overlap: 50

# Memory settings
memory:
  enabled: true
  max_history_turns: 20
  summarization:
    enabled: true
    trigger_length: 10
```

---

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| [SYSTEM_ARCHITECTURE.md](SYSTEM_ARCHITECTURE.md) | Comprehensive system architecture with data flow diagrams |
| [READY_FOR_EXPERIMENTS.md](READY_FOR_EXPERIMENTS.md) | Complete experiment execution guide |
| [SYSTEM_READINESS_REPORT.md](SYSTEM_READINESS_REPORT.md) | Pre-experiment system validation |
| [DATA_COLLECTION_GUIDE.md](DATA_COLLECTION_GUIDE.md) | Privacy-preserving data collection |
| [DATA_SOURCES.md](DATA_SOURCES.md) | Data sources and synthetic data justification |
| [PROJECT_STATUS.md](PROJECT_STATUS.md) | Overall project status |

---

## ğŸ³ Docker Deployment

```bash
# Build image
docker build -t contraception-counseling:latest .

# Run with Docker Compose
docker-compose up -d

# View logs
docker-compose logs -f

# Stop
docker-compose down
```

---

## ğŸ§ª Testing

```bash
# Run unit tests
pytest tests/

# Run with coverage
pytest --cov=src tests/

# Run integration tests
pytest tests/integration/
```

---

## ğŸ” Monitoring

### Logging
- **Level**: INFO (configurable)
- **Format**: Structured JSON
- **Rotation**: 100 MB, 30 days retention
- **Location**: `results/logs/`

### Performance
- **Embedding**: ~0.05s per query
- **Vector Search**: ~0.01s (5,460 chunks)
- **LLM Generation**: 2-5s (depends on length)
- **Total Latency**: 2-6s (end-to-end)

### Resource Usage
- **RAM**: ~4-8 GB (depends on model)
- **Disk**: ~7 GB (models + data)
- **CPU**: Multi-core recommended

---

## ğŸš¦ Status & Roadmap

### âœ… Completed
- Core RAG pipeline with WHO/BCS+ guidelines
- Multi-language support (EN/FR/RW)
- Memory management and user profiles
- Privacy-first data collection
- Comprehensive evaluation framework
- Web-based chat interface
- REST API with 21 endpoints
- Docker containerization
- Experiment runner with validation

### ğŸš§ Future Enhancements
- Cloud deployment guides (AWS, Azure, GCP)
- Mobile application (React Native)
- Advanced adherence support
- Real-time analytics dashboard
- A/B testing framework
- Model fine-tuning pipeline

---

## ğŸ“– Academic Context

This is a **graduate-level capstone project** demonstrating:

- **Production-ready system**: FastAPI, Docker, comprehensive testing
- **Research rigor**: 6 experiments, statistical analysis, reproducibility
- **Privacy compliance**: GDPR, anonymous data, opt-in collection
- **Multilingual NLP**: Language-specific model routing
- **Evaluation depth**: BERTScore, hallucination detection, citation accuracy
- **Documentation**: Architecture diagrams, data flow, API specs

### Key Contributions
1. **RAG for Medical Counseling**: Guideline-grounded responses with source attribution
2. **Multi-Language Healthcare AI**: Language-specific routing eliminates translation issues
3. **Privacy-Preserving Data Collection**: Anonymous, opt-in, GDPR-compliant
4. **Comprehensive Evaluation**: Beyond accuracy - hallucination, citations, safety

---

## ğŸ™ Acknowledgments

### Data Sources
- **WHO Family Planning Handbook 2022** - Primary medical guidelines
- **BCS+ Toolkit** - Comprehensive counseling framework

### Technologies
- **Ollama** - Local LLM inference
- **Meta (llama3.2)** - English/French generation
- **Cohere (Aya)** - Kinyarwanda generation
- **Sentence Transformers** - Semantic embeddings
- **FAISS** - Efficient similarity search
- **FastAPI** - Modern Python web framework

---

## ğŸ“§ Contact

For questions or collaboration:
- Create an issue in the repository
- See [PROJECT_STATUS.md](PROJECT_STATUS.md) for project updates

---

## ğŸ“„ License

MIT License - See LICENSE file for details

---

## ğŸ“ Citation

If you use this system in your research, please cite:

```bibtex
@software{ai_contraception_counseling_2025,
  title={AI Contraception Counseling System: RAG-based Evidence Grounding},
  author={[Your Name]},
  year={2025},
  url={https://github.com/[your-repo]}
}
```

---

**Built with â¤ï¸ for improving global access to evidence-based contraception counseling**

**Status**: Production Ready âœ…
**Last Updated**: December 1, 2025
